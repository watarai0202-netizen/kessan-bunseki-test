from __future__ import annotations

import hashlib
import re
from datetime import datetime, timedelta, timezone

import streamlit as st

from src.tdnet import fetch_tdnet_items
from src.analyzer import analyze_pdf_to_json, ai_is_enabled
from src.storage import init_db, get_cached_analysis, save_analysis, db_path_default
from src.viz import render_analysis


# ----------------------------
# Constants / Helpers
# ----------------------------
JST = timezone(timedelta(hours=9))

_KESSAN_RE = re.compile(
    r"(æ±ºç®—çŸ­ä¿¡|å››åŠæœŸæ±ºç®—|é€šæœŸæ±ºç®—|Financial Results|Earnings)",
    re.IGNORECASE
)

def is_kessan(title: str) -> bool:
    return bool(_KESSAN_RE.search(title or ""))

def fmt_dt(dt: datetime | None) -> str:
    if not dt:
        return "ä¸æ˜"
    try:
        return dt.astimezone(JST).strftime("%Y-%m-%d %H:%M JST")
    except Exception:
        return str(dt)

def make_uid(it: dict, i: int) -> str:
    title = (it.get("title") or "").strip()
    code_ = (it.get("code") or "").strip()
    doc_url = (it.get("doc_url") or "").strip()
    link = (it.get("link") or "").strip()
    published = it.get("published_at")
    seed = f"{code_}|{published}|{title}|{doc_url}|{link}|{i}"
    return hashlib.md5(seed.encode("utf-8")).hexdigest()[:12]


# ----------------------------
# Page
# ----------------------------
st.set_page_config(page_title="æ±ºç®—çŸ­ä¿¡ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼", layout="wide")

# ----------------------------
# Auth (simple password gate)
# ----------------------------
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
if not APP_PASSWORD:
    st.error("APP_PASSWORD ãŒæœªè¨­å®šã§ã™ï¼ˆStreamlit Cloud ã® Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ï¼‰")
    st.stop()

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("èªè¨¼ãŒå¿…è¦ã§ã™")
    pw = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pw == APP_PASSWORD:
        st.session_state.authenticated = True
        st.rerun()
    st.stop()

# ----------------------------
# DB init (cache store)
# ----------------------------
DB_PATH = st.secrets.get("DB_PATH", db_path_default())
init_db(DB_PATH)

MAX_PDF_BYTES = int(st.secrets.get("MAX_PDF_BYTES", 20 * 1024 * 1024))

# ----------------------------
# Header
# ----------------------------
st.title("ğŸ“ˆ æ±ºç®—çŸ­ä¿¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° & ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚º")
st.caption("ç‹™ã„ï¼šã‚¹ãƒãƒ›ã§ã‚‚ã€ŒéŠ˜æŸ„â†’é–‹ç¤ºâ†’è¦ç‚¹ï¼‹æ•°å€¤ã€ã¾ã§æœ€çŸ­ã§è¦‹ã‚‹ã€‚AIè¦ç´„ã¯æŠ¼ã—ãŸæ™‚ã ã‘å®Ÿè¡Œã€‚")
st.caption(f"PDFä¸Šé™: {MAX_PDF_BYTES/1024/1024:.1f}MBï¼ˆè¶…ãˆã‚‹ã¨è§£æå¤±æ•—ã—ã‚„ã™ã„ï¼‰")

# ----------------------------
# Screening controls
# ----------------------------
with st.expander("ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶", expanded=True):
    col1, col2, col3 = st.columns([2, 2, 2])

    with col1:
        code = st.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆ4æ¡ã€ç©ºãªã‚‰ç›´è¿‘å…¨ä½“ï¼‰", value="").strip()
        only_kessan = st.checkbox("æ±ºç®—çŸ­ä¿¡ã ã‘ã«çµã‚‹", value=True)

    with col2:
        days = st.slider("ç›´è¿‘ä½•æ—¥ã‚’è¦‹ã‚‹ï¼Ÿ", 1, 30, 7)
        limit = st.slider("å–å¾—ä»¶æ•°ï¼ˆå¤§ãã„ã»ã©é…ã„ï¼‰", 50, 1000, 300)

    with col3:
        # æœ€åˆã¯OFFæ¨å¥¨ï¼ˆdoc_urlãŒå–ã‚Œã¦ã‚‹ã‹ç¢ºèªã—ã¦ã‹ã‚‰ONã«ï¼‰
        only_has_doc_url = st.checkbox("PDF URLãŒã‚ã‚‹ã‚‚ã®ã ã‘", value=False)
        show_ai_button = st.checkbox("AIåˆ†æãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º", value=True)
        show_debug = st.checkbox("DEBUGè¡¨ç¤ºï¼ˆå…ˆé ­5ä»¶ã®JSONï¼‰", value=False)

# sanity for code
if code and (not code.isdigit() or len(code) != 4):
    st.warning("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¯4æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š7203ï¼‰")
    code = ""

# ----------------------------
# Fetch TDnet items
# ----------------------------
cutoff_utc = datetime.now(timezone.utc) - timedelta(days=days)

with st.spinner("é–‹ç¤ºä¸€è¦§ã‚’å–å¾—ä¸­..."):
    try:
        items = fetch_tdnet_items(code or None, limit=limit) or []
    except Exception as e:
        st.error(f"TDnetå–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        st.stop()

if show_debug:
    with st.expander("DEBUG: itemså…ˆé ­5ä»¶ï¼ˆtitle/doc_url/linkã®ç¢ºèªï¼‰", expanded=False):
        st.json(items[:5])

if not items:
    st.info("TDnetã‹ã‚‰å–å¾—ã§ããŸä»¶æ•°ãŒ0ã§ã™ã€‚fetch_tdnet_items ã®å–å¾—å…ˆã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# Filter
# ----------------------------
filtered: list[dict] = []
for it in items:
    title = (it.get("title") or "").strip()
    doc_url = (it.get("doc_url") or "").strip()
    published = it.get("published_at")

    if only_kessan and (not is_kessan(title)):
        continue
    if only_has_doc_url and not doc_url:
        continue
    if published and published < cutoff_utc:
        continue

    filtered.append(it)

st.subheader(f"å€™è£œï¼š{len(filtered)}ä»¶")

if not filtered:
    st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹é–‹ç¤ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥æ•°/ä»¶æ•°/ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ----------------------------
# AI availability
# ----------------------------
ai_ok = ai_is_enabled()
if show_ai_button and not ai_ok:
    st.warning("Gemini APIã‚­ãƒ¼æœªè¨­å®šã®ãŸã‚ã€AIåˆ†æã¯ç„¡åŠ¹ã§ã™ã€‚Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# ----------------------------
# Render list (mobile-friendly)
# ----------------------------
for i, it in enumerate(filtered[:200]):
    uid = make_uid(it, i)

    title = (it.get("title") or "").strip()
    code_ = (it.get("code") or "").strip()
    doc_url = (it.get("doc_url") or "").strip()
    link = (it.get("link") or "").strip()
    published = it.get("published_at")

    label = f"{code_ or '----'}ï½œ{fmt_dt(published)}ï½œ{title[:60]}"
    with st.expander(label, expanded=False):
        if doc_url:
            st.caption(f"PDF: {doc_url}")
        elif link:
            st.caption(f"Link: {link}ï¼ˆPDF URLãŒç„¡ã„ã®ã§AIè§£æä¸å¯ï¼‰")
        else:
            st.caption("URLæƒ…å ±ãªã—ï¼ˆAIè§£æä¸å¯ï¼‰")

        cached = get_cached_analysis(DB_PATH, doc_url) if doc_url else None
        if cached:
            st.success("è§£ææ¸ˆã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰")
            render_analysis(cached)
        else:
            st.info("æœªè§£æ")

        # ãƒœã‚¿ãƒ³ä½œæˆå‰ã«è¨ˆç®—ã—ã¦ãŠãï¼ˆdisabledãŒåŠ¹ãï¼‰
        can_run_ai = show_ai_button and ai_ok and bool(doc_url)

        cols = st.columns([1, 1, 3])

        with cols[0]:
            if st.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¡¨ç¤º", key=f"show_{uid}", disabled=(not bool(cached))):
                render_analysis(cached)

        with cols[1]:
            run = st.button("AIåˆ†æ", key=f"ai_{uid}", disabled=not can_run_ai)

        with cols[2]:
            st.caption("â€»åŒã˜PDF URLã¯SQLiteã«ä¿å­˜ã—ã€å†è§£æã—ã¾ã›ã‚“ï¼ˆDBã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰±ã„ï¼‰ã€‚")

        if run:
            with st.spinner("AIãŒæ±ºç®—çŸ­ä¿¡ã‚’è§£æä¸­..."):
                try:
                    payload = analyze_pdf_to_json(doc_url)
                    save_analysis(DB_PATH, doc_url, code_, title, published, payload)
                    st.success("è§£æå®Œäº†")
                    render_analysis(payload)
                except Exception as e:
                    st.error(f"è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

st.divider()

# ----------------------------
# Manual analyze
# ----------------------------
st.subheader("æ‰‹å‹•è§£æï¼ˆURLã‚’è²¼ã‚‹ï¼‰")
st.caption("â€»ã¾ãšã¯PDF URLæ¨å¥¨ã€‚HTMLã®URLã¯å¤±æ•—ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")

manual = st.text_input("URLï¼ˆ.pdfæ¨å¥¨ï¼‰", value="").strip()
colA, colB = st.columns([1, 3])
with colA:
    manual_run = st.button("AIè§£æ", disabled=not (ai_ok and manual))
with colB:
    st.caption("Geminiæœªè¨­å®šãªã‚‰Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

if manual_run:
    with st.spinner("AIãŒè§£æä¸­..."):
        try:
            payload = analyze_pdf_to_json(manual)
            st.success("è§£æå®Œäº†")
            try:
                render_analysis(payload)
            except Exception:
                st.json(payload)
        except Exception as e:
            st.error(f"è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
