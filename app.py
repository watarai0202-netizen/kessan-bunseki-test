from __future__ import annotations

import hashlib
import json
import re
import sqlite3
from datetime import datetime, timedelta, timezone
from typing import Any, Optional

import streamlit as st

from src.tdnet import fetch_tdnet_items
from src.analyzer import summarize_kessan_pdf

APP_TITLE = "æ±ºç®—çŸ­ä¿¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚º"
DB_PATH = "app.db"

_KESSAN_RE = re.compile(r"(æ±ºç®—çŸ­ä¿¡|å››åŠæœŸæ±ºç®—|é€šæœŸæ±ºç®—|Financial Results|Earnings)", re.IGNORECASE)


def is_kessan(title: str) -> bool:
    return bool(_KESSAN_RE.search(title or ""))


def get_secret(name: str, default: str = "") -> str:
    try:
        v = st.secrets.get(name)
        if v is None:
            return default
        return str(v).strip()
    except Exception:
        return default


def init_db() -> None:
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS analysis_cache (
            key TEXT PRIMARY KEY,
            pdf_url TEXT,
            code TEXT,
            company_name TEXT,
            title TEXT,
            published_at TEXT,
            result TEXT,
            created_at TEXT
        )
        """
    )
    con.commit()
    con.close()


def cache_key(pdf_url: str) -> str:
    return hashlib.sha256((pdf_url or "").encode("utf-8")).hexdigest()


def get_cached(pdf_url: str) -> Optional[dict[str, Any]]:
    k = cache_key(pdf_url)
    con = sqlite3.connect(DB_PATH)
    con.row_factory = sqlite3.Row
    cur = con.cursor()
    cur.execute("SELECT * FROM analysis_cache WHERE key = ?", (k,))
    row = cur.fetchone()
    con.close()
    if not row:
        return None
    return dict(row)


def set_cached(pdf_url: str, code: str, company_name: str, title: str, published_at: str, result: str) -> None:
    k = cache_key(pdf_url)
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        """
        INSERT OR REPLACE INTO analysis_cache
        (key, pdf_url, code, company_name, title, published_at, result, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """,
        (k, pdf_url, code, company_name, title, published_at, result, datetime.now(timezone.utc).isoformat()),
    )
    con.commit()
    con.close()


def unwrap_tdnet_pdf(url: str) -> str:
    """
    src/tdnet.pyå´ã§ã‚‚unwrapã—ã¦ã‚‹ãŒã€UIå´ã§ã‚‚å¿µã®ãŸã‚ã€‚
    """
    u = (url or "").strip()
    if not u:
        return ""
    if "webapi.yanoshin.jp/rd.php?" in u:
        try:
            return u.split("rd.php?", 1)[1].strip()
        except Exception:
            return u
    return u


def is_pdf_url(url: str) -> bool:
    u = (url or "").strip().lower()
    return u.endswith(".pdf") or ".pdf?" in u


def within_days(dt: Optional[datetime], days: int) -> bool:
    if not dt:
        return True
    now = datetime.now(timezone.utc)
    return dt >= now - timedelta(days=days)


def require_login() -> None:
    # ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆSecretsã§APP_PASSWORDãŒæœªè¨­å®šãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    app_pw = get_secret("APP_PASSWORD", "")
    if not app_pw:
        return

    if "authed" not in st.session_state:
        st.session_state.authed = False

    if st.session_state.authed:
        return

    st.warning("ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¿è­·ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    pw = st.text_input("Password", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if pw == app_pw:
            st.session_state.authed = True
            st.success("ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸã€‚")
            st.rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")
    st.stop()


def main() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    init_db()

    require_login()

    st.title("ğŸ“ˆ " + APP_TITLE)
    st.caption("ç‹™ã„ï¼šã‚¹ãƒãƒ›ã§ã‚‚ã€éŠ˜æŸ„/é–‹ç¤º/è¦ç‚¹ï¼‹æ•°å€¤ã€ã¾ã§æœ€çŸ­ã§è¦‹ã‚‹ã€‚AIè¦ç´„ã¯æŠ¼ã—ãŸæ™‚ã ã‘å®Ÿè¡Œã€‚")

    gemini_api_key = get_secret("GEMINI_API_KEY", "") or get_secret("GOOGLE_API_KEY", "")
    gemini_model = get_secret("GEMINI_MODEL", "gemini-2.0-flash")
    max_pdf_bytes = int(get_secret("MAX_PDF_BYTES", "21000000"))

    can_run_ai = bool(gemini_api_key)

    if not can_run_ai:
        st.info("Gemini APIã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ã€‚Streamlit Secrets ã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    st.caption(f"PDFä¸Šé™: {max_pdf_bytes/1_000_000:.1f}MBï¼ˆSecrets ã® MAX_PDF_BYTES ã§å¤‰æ›´å¯ï¼‰")

    with st.expander("ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶", expanded=True):
        colL, colM, colR = st.columns([2, 3, 2])

        with colL:
            code_input = st.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆ4æ¡ã€ç©ºãªã‚‰ç›´è¿‘å…¨ä½“ï¼‰", value="", placeholder="ä¾‹ï¼š8170")
            only_kessan = st.checkbox("æ±ºç®—çŸ­ä¿¡ã ã‘ã«çµã‚‹ï¼ˆ0ä»¶ãªã‚‰è‡ªå‹•ã§åºƒã‚ã«åˆ‡æ›¿ï¼‰", value=True)

        with colM:
            days = st.slider("ç›´è¿‘ä½•æ—¥ã‚’è¦‹ã‚‹ï¼Ÿ", min_value=1, max_value=30, value=12)
            limit = st.slider("å–å¾—ä»¶æ•°ï¼ˆå¤§ãã„ã»ã©é…ã„ï¼‰", min_value=50, max_value=500, value=300, step=50)

        with colR:
            only_pdf = st.checkbox("PDF URLãŒã‚ã‚‹ã‚‚ã®ã ã‘", value=False)
            show_ai_btn = st.checkbox("AIåˆ†æãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º", value=True)
            show_debug = st.checkbox("DEBUGè¡¨ç¤ºï¼ˆå…ˆé ­5ä»¶ã®JSONï¼‰", value=False)

    # ---- ãƒ‡ãƒ¼ã‚¿å–å¾— ----
    items = fetch_tdnet_items(code_input.strip() if code_input else None, limit=limit)

    if show_debug:
        st.write("DEBUG: itemså…ˆé ­5ä»¶ï¼ˆtitle/doc_url/published/company_nameã®ç¢ºèªï¼‰")
        st.json(items[:5])

    # ---- ãƒ•ã‚£ãƒ«ã‚¿ ----
    # ã¾ãšã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¡ä»¶ã§çµã‚‹
    filtered: list[dict[str, Any]] = []
    for it in items:
        title = it.get("title", "") or ""
        dt = it.get("published_at")
        doc_url = unwrap_tdnet_pdf(it.get("doc_url", "") or "")

        if not within_days(dt, days):
            continue
        if only_pdf and not (doc_url and is_pdf_url(doc_url)):
            continue
        if only_kessan and not is_kessan(title):
            continue

        filtered.append(it)

    # 0ä»¶ãªã‚‰è‡ªå‹•ã§ç·©ã‚ã‚‹ï¼ˆå£Šã‚Œãªã„ç¯„å›²ã§ï¼‰
    relaxed_note = ""
    if only_kessan and len(filtered) == 0 and len(items) > 0:
        # æ±ºç®—ãƒ•ã‚£ãƒ«ã‚¿ã ã‘å¤–ã—ã¦å†å®Ÿè¡Œ
        for it in items:
            dt = it.get("published_at")
            doc_url = unwrap_tdnet_pdf(it.get("doc_url", "") or "")
            if not within_days(dt, days):
                continue
            if only_pdf and not (doc_url and is_pdf_url(doc_url)):
                continue
            filtered.append(it)
        relaxed_note = "ï¼ˆæ±ºç®—çŸ­ä¿¡ãƒ•ã‚£ãƒ«ã‚¿ã§0ä»¶ã ã£ãŸãŸã‚ã€è‡ªå‹•ã§ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç·©ã‚ã¦è¡¨ç¤ºã—ã¦ã„ã¾ã™ï¼‰"

    st.subheader(f"å€™è£œï¼š{len(filtered)}ä»¶ {relaxed_note}")

    if len(filtered) == 0:
        st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹é–‹ç¤ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥æ•°/ä»¶æ•°/ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return

    # è¡¨ç¤ºä¸Šé™ï¼ˆé‡ã„ã®ã§æœ€åˆã¯æœ€å¤§100ä»¶ï¼‰
    show_n = min(len(filtered), 120)
    st.caption(f"è¡¨ç¤ºï¼šå…ˆé ­ {show_n} ä»¶ï¼ˆé‡ã„å ´åˆã¯ä»¶æ•°ã‚’ä¸‹ã’ã¦ãã ã•ã„ï¼‰")

    for i, it in enumerate(filtered[:show_n]):
        title = it.get("title", "") or ""
        code4 = (it.get("code") or it.get("code4") or "").strip()
        company_name = (it.get("company_name") or "").strip()
        published = it.get("published_at")
        doc_url_raw = (it.get("doc_url") or "").strip()
        doc_url = unwrap_tdnet_pdf(doc_url_raw)

        pub_str = published.isoformat() if isinstance(published, datetime) else ""

        # Streamlit DuplicateElementKey å¯¾ç­–ï¼šå†…å®¹ã«ä¾å­˜ã™ã‚‹UID
        seed = f"{code4}|{company_name}|{pub_str}|{title}|{doc_url}|{i}"
        uid = hashlib.md5(seed.encode("utf-8")).hexdigest()[:12]

        # ãƒ˜ãƒƒãƒ€è¡¨ç¤ºï¼ˆã‚³ãƒ¼ãƒ‰æ¨ªã«ç¤¾åï¼‰
        left = f"{code4}" if code4 else "----"
        if company_name:
            left += f"ï½œ{company_name}"

        head = f"{left}ï½œ{published.strftime('%Y-%m-%d %H:%M')} UTCï½œ{title}" if isinstance(published, datetime) else f"{left}ï½œ{title}"

        with st.expander(head, expanded=False):
            # URLæƒ…å ±
            if doc_url:
                st.write(f"PDF: {doc_url}")
            else:
                st.caption("URLæƒ…å ±ãªã—ï¼ˆAIè§£æä¸å¯ï¼‰")

            cached = get_cached(doc_url) if doc_url else None
            status = "è§£ææ¸ˆã¿" if (cached and cached.get("result")) else "æœªè§£æ"
            st.write(f"çŠ¶æ…‹: {status}")

            cols = st.columns([1, 1, 3])

            with cols[0]:
                if st.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¡¨ç¤º", key=f"show_{uid}", disabled=not bool(doc_url)):
                    if not doc_url:
                        st.warning("PDF URLãŒç„¡ã„ãŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‚ç…§ã§ãã¾ã›ã‚“ã€‚")
                    else:
                        c = get_cached(doc_url)
                        if not c:
                            st.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
                        else:
                            st.text_area("ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµæœ", c.get("result", ""), height=260)

            with cols[1]:
                # AIåˆ†æ
                disabled_ai = (not show_ai_btn) or (not can_run_ai) or (not bool(doc_url)) or (not is_pdf_url(doc_url))
                btn_help = ""
                if not show_ai_btn:
                    btn_help = "ï¼ˆAIåˆ†æãƒœã‚¿ãƒ³è¡¨ç¤ºãŒOFFï¼‰"
                elif not can_run_ai:
                    btn_help = "ï¼ˆGEMINI_API_KEY æœªè¨­å®šï¼‰"
                elif not doc_url:
                    btn_help = "ï¼ˆPDF URLãªã—ï¼‰"
                elif not is_pdf_url(doc_url):
                    btn_help = "ï¼ˆPDFã§ã¯ãªã„URLï¼‰"

                if st.button(f"AIåˆ†æ{btn_help}", key=f"ai_{uid}", disabled=disabled_ai):
                    # æ—¢ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹ãªã‚‰ãã‚Œã‚’å‡ºã™ï¼ˆå†è§£æã—ãªã„ï¼‰
                    c = get_cached(doc_url)
                    if c and c.get("result"):
                        st.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¡¨ç¤ºã—ã¾ã™ï¼ˆå†è§£æã—ã¾ã›ã‚“ï¼‰ã€‚")
                        st.text_area("AIè¦ç´„", c["result"], height=320)
                    else:
                        with st.spinner("PDFã‚’å–å¾—ã—ã¦Geminiã§è¦ç´„ä¸­..."):
                            res = summarize_kessan_pdf(
                                pdf_url=doc_url,
                                gemini_api_key=gemini_api_key,
                                gemini_model=gemini_model,
                                max_pdf_bytes=max_pdf_bytes,
                            )
                        if not res.ok:
                            st.error(res.error or "è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        else:
                            result_text = res.text
                            set_cached(
                                pdf_url=doc_url,
                                code=code4,
                                company_name=company_name,
                                title=title,
                                published_at=pub_str,
                                result=result_text,
                            )
                            st.success("è§£æå®Œäº†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜æ¸ˆã¿ï¼‰")
                            st.text_area("AIè¦ç´„", result_text, height=360)

            with cols[2]:
                st.caption("â€»åŒã˜PDF URLã¯SQLiteã«ä¿å­˜ã—ã€å†è§£æã—ã¾ã›ã‚“ï¼ˆDBã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰±ã„ï¼‰ã€‚")


if __name__ == "__main__":
    main()
